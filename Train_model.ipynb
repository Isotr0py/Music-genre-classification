{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Deal with GTZAN Dataset\n","- Read GTZAN Dataset\n","- extract and resample features\n","- save features and labels to numpy file"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T05:25:14.050647Z","iopub.status.busy":"2022-07-11T05:25:14.050234Z","iopub.status.idle":"2022-07-11T05:32:00.801316Z","shell.execute_reply":"2022-07-11T05:32:00.800166Z","shell.execute_reply.started":"2022-07-11T05:25:14.050559Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import librosa\n","import os\n","from tqdm import tqdm\n","from scipy import signal\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# extract and resample features\n","def featureCal(y,sr,times_len):\n","    chroma_stft = librosa.feature.chroma_stft(y,sr)                 # chroma\n","    spectral_center = librosa.feature.spectral_centroid(y=y, sr=sr) # spectral_center\n","    mfcc = librosa.feature.mfcc(y,sr,n_mfcc=20)                     # mfcc\n","    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)   # spectral_contrast\n","    # print(chroma_stft.shape,spectral_center.shape,mfcc.shape,spectral_contrast.shape)\n","    features = chroma_stft.copy()\n","    for feature in [spectral_center,mfcc,spectral_contrast]:\n","        features = np.append(features,feature,axis=0)\n","    features = signal.resample(features,times_len,axis=1)   # resample\n","    return features[:,:times_len]\n","\n","genres = os.listdir('../input/gtzan-genre-collection/genres/')\n","genres.sort()\n","print(genres)\n","\n","# read gtzan dataset\n","features = []\n","labels = []\n","for i,genre in enumerate(genres):\n","    files = os.listdir(f'../input/gtzan-genre-collection/genres/{genre}/')\n","    files.sort()\n","    for file in tqdm(files):\n","        y,sr = librosa.load(f\"../input/gtzan-genre-collection/genres/{genre}/{file}\")\n","        feature = featureCal(y,sr,times_len=256)\n","        features.append(feature)\n","        labels.append(i)\n","features = np.stack(features)   # stack feature from each file\n","labels = np.array(labels)\n","# np.save(f\"{genre}_features.npy\",features)\n","# np.save(f\"{genre}_labels.npy\",labels)\n","# features = np.stack(features)\n","np.save(f\"features.npy\",features)\n","np.save(f\"labels.npy\",labels)"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T03:38:33.454322Z","iopub.status.busy":"2022-07-11T03:38:33.453873Z","iopub.status.idle":"2022-07-11T03:38:34.334774Z","shell.execute_reply":"2022-07-11T03:38:34.333282Z","shell.execute_reply.started":"2022-07-11T03:38:33.454278Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from sklearn.model_selection import train_test_split \n","from sklearn.preprocessing import StandardScaler\n","\n","# features = np.load(\"../input/cnnmusic/features.npy\")\n","# labels = np.load(\"../input/cnnmusic/labels.npy\")\n","features = np.load(\"./features.npy\")\n","labels = np.load(\"./labels.npy\")\n","\n","# normalize features, shape(files,time_series,features)\n","features = np.transpose(features,[0,2,1])\n","scaler = StandardScaler()\n","for i in range(features.shape[0]):\n","    features[i,:,:] = scaler.fit_transform(features[i,:,:])\n","print(features.shape)\n","x_train,x_test,y_train,y_test=train_test_split(features,labels,test_size=0.3,random_state=0)   #划分验证集, 70% for train 30% for test\n","print(x_train.shape)\n","print(y_train.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Train model\n","    Model Summary:\n","    _________________________________________________________________\n","    Layer (type)                Output Shape              Param #\n","    =================================================================\n","    conv1d_1 (Conv1D)          (None, 252, 64)           12864\n","    _________________________________________________________________\n","    dropout_1 (Dropout)        (None, 252, 64)           0\n","    _________________________________________________________________\n","    max_pooling1d_1 (MaxPoolin  (None, 126, 64)          0\n","    g1D)\n","    _________________________________________________________________\n","    conv1d_2 (Conv1D)          (None, 122, 32)           10272\n","    _________________________________________________________________\n","    conv1d_3 (Conv1D)          (None, 118, 16)           2576\n","    _________________________________________________________________\n","    dropout_2 (Dropout)        (None, 118, 16)           0\n","    _________________________________________________________________\n","    global_average_pooling1d_1  (None, 16)               0\n","    (GlobalAveragePooling1D)\n","    _________________________________________________________________\n","    flatten_1 (Flatten)        (None, 16)                0\n","    _________________________________________________________________\n","    dense_1 (Dense)            (None, 10)                170\n","    =================================================================\n","    Total params: 25,882\n","    Trainable params: 25,882\n","    Non-trainable params: 0\n","    ________________________________\n","    Training X shape: (700, 256, 40)\n","    Training Y shape: (700)\n","    ________________________________\n","    Test X shape: (300, 256, 40)\n","    Test Y shape: (300)"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T03:41:19.970649Z","iopub.status.busy":"2022-07-11T03:41:19.969919Z","iopub.status.idle":"2022-07-11T03:41:58.058924Z","shell.execute_reply":"2022-07-11T03:41:58.058002Z","shell.execute_reply.started":"2022-07-11T03:41:19.970602Z"},"trusted":true},"outputs":[],"source":["from keras import models\n","from keras import layers\n","\n","# Convolute along time axis\n","model = models.Sequential()\n","model.add(layers.Conv1D(64,5,activation='relu',input_shape=x_train.shape[1:]))  # input_shape = (time_series,features)\n","model.add(layers.Dropout(0.8))\n","model.add(layers.MaxPooling1D(pool_size=2))\n","model.add(layers.Conv1D(32,5,activation='relu'))\n","model.add(layers.Conv1D(16,5,activation='relu'))\n","model.add(layers.Dropout(0.8))\n","model.add(layers.GlobalAveragePooling1D())\n","model.add(layers.Flatten())                 # flatten for dense input\n","model.add(layers.Dense(10, activation='softmax'))\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.summary()\n","\n","history = model.fit(x_train,y_train,epochs=400,batch_size=32)   # train\n","test_loss, test_acc = model.evaluate(x_test,y_test)             # test\n","print('test_acc: ',test_acc)\n","predictions = model.predict(x_test)\n","model.save('Audino_CNN')"]},{"cell_type":"markdown","metadata":{},"source":["## Assess classification accuracy"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2022-07-11T03:42:11.698558Z","iopub.status.busy":"2022-07-11T03:42:11.697683Z","iopub.status.idle":"2022-07-11T03:42:12.251291Z","shell.execute_reply":"2022-07-11T03:42:12.250299Z","shell.execute_reply.started":"2022-07-11T03:42:11.698523Z"},"trusted":true},"outputs":[],"source":["classlist = ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n","predixt = np.argmax(predictions,axis=1)\n","for i, j in zip(y_test[:20], predixt[:20]):\n","    print(f\"Predict:{classlist[int(j)]:<10}Real:{classlist[int(i)]:<10}Status:{i==j}\")\n","\n","from sklearn.metrics import confusion_matrix\n","matrix = confusion_matrix(y_test,predixt)   # calculate confusion_matrix\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# visualize confusion_matrix with heatmap\n","plt.figure(figsize=[10,10])\n","sns.heatmap(matrix,cmap='Blues',annot=True,fmt='.20g',xticklabels=classlist,yticklabels=classlist)\n","plt.xlabel('Predict')\n","plt.ylabel('Real')\n","np.save('matrix',matrix)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.7 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"7570b1e8f61885eb4b5d4c49429a141c68dbd5f171fb81665b3780be79ab3250"}}},"nbformat":4,"nbformat_minor":4}
